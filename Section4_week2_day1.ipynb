{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section4_week2_day1",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPyIzD99u3BGmluUHrAucyV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jungseunggi/Section4_week2/blob/main/Section4_week2_day1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. 자연어처리(NLP, Natural Language Processing)**"
      ],
      "metadata": {
        "id": "MrJv5VMJRczV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1.1 자연어 처리란??**\n"
      ],
      "metadata": {
        "id": "R3c3aE25RjtW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NLP(처리) vs NLU(이해) vs NLG(생성) 자연어처리 개념 차이점**"
      ],
      "metadata": {
        "id": "Wy_t7TgsKzFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://www.ibm.com/blogs/watson/wp-content/uploads/2020/11/Leadspace.jpg' width=600>\n",
        "\n",
        "<sub>이미지 출처 : https://www.ibm.com/blogs/watson/wp-content/uploads/2020/11/Leadspace.jpg"
      ],
      "metadata": {
        "id": "EVtJKNjkKnCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* NLP, NLU, NLG 모두 관련된 주제이지만 별개의 주제\n",
        "\n",
        "* 높은 수준에서 NLU와 NLG는 NLP의 구성 요소"
      ],
      "metadata": {
        "id": "AOFKoM3sLJ5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**자연어란??**\n",
        "\n",
        "* 우리가 일상생활에서 쓰는 언어를 말함\n",
        "\n",
        "**NLP(자연어처리)란??** \n",
        "\n",
        "* 다양한 분야의 방법을 사용하여 컴퓨터가 문자 및 언어 형태로 인간 언어를 이해할 수 있도록 하는 것\n",
        "\n",
        "* 컴퓨터 언어학은 언어 측면에 더 중점을 두지만 자연어 처리는 머신러닝,딥러닝 기술을 사용하여 언어 번역이나 질문 답변과 같은 작업을 완료하는 것을 강조\n",
        "\n",
        "* 자연어 처리는 구조화되지 않은 데이터를 가져와 구조화된 데이터 형식으로 변환하는 방식으로 작동\n",
        "\n",
        "**NLU(자연어이해)란??**\n",
        "\n",
        "* 문장의 의미를 결정하기 위해 텍스트와 음성의 구문 및 의미 분석을 사용하는 자연어 처리의 하위 집합\n",
        "\n",
        "* 단어와 구 간의 관계를 지정하는 데이터 구조를 설정\n",
        "\n",
        "* 인간은 대화를 통해 자연스럽게 이를 수행하지만 기계가 다른 텍스트의 의도된 의미를 이해하려면 이러한 분석의 조합이 필요\n",
        "\n",
        "* 'Alice is swimming against the current', 'The current version of the report is in the folder' 이 두문장에서의 current는 명사, 형용사로 사용\n",
        "\n",
        "**NLG(자연어생성)란??**\n",
        "\n",
        "* 자연어 생성은 자연어 처리의 또 다른 하위 집합\n",
        "\n",
        "* 자연어 이해는 컴퓨터 읽기 이해에 초점을 맞추는 반면, 자연어 생성은 컴퓨터가 쓸 수 있도록 함\n",
        "* NLU와 마찬가지로 NLG 애플리케이션은 응답을 적절하게 표현하는 방법을 선택하기 위해 형태, 어휘, 구문 및 의미를 기반으로 하는 언어 규칙을 고려\n",
        "\n",
        "**정리하자면**\n",
        "\n",
        "* 자연어 처리(NLP) 는 기계가 음성과 텍스트를 이해하고 관련 문맥 응답을 공식화할 수 있도록 비정형 언어 데이터를 구조화된 데이터 형식으로 변환, 하위 주제에는 자연어 처리 및 자연어 생성이 포함\n",
        "\n",
        "* 자연어 이해(NLU) 는 문법과 문맥을 통한 기계 읽기 이해에 중점을 두어 문장의 의도된 의미를 결정할 수 있음\n",
        "* 자연어 생성(NLG) 은 주어진 데이터 세트를 기반으로 기계에 의한 텍스트 생성 또는 영어 또는 기타 언어의 텍스트 구성에 중점"
      ],
      "metadata": {
        "id": "8kaiYLx1RvME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1.2 NLP 작업**"
      ],
      "metadata": {
        "id": "RSHYWDGwGxtS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "여러 NLP 작업은 컴퓨터가 수집하는 내용을 이해하는 데 도움이 되는 방식으로 사람의 텍스트와 음성 데이터를 분해하며 이러한 작업 중 일부는 다음과 같음"
      ],
      "metadata": {
        "id": "x3PLquGIG5O3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Speech recognition**\n",
        "\n",
        "* 음성 인식 은 음성 데이터를 텍스트 데이터로 안정적으로 변환하는 작업\n",
        "* 음성 인식을 특히 어렵게 만드는 것은 사람들이 말하는 방식\n",
        "* 다양한 강조와 억양, 다양한 억양, 종종 잘못된 문법을 사용하여 단어를 함께 빠르게, 모호하게 만듬"
      ],
      "metadata": {
        "id": "G3PrKCc9HM-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part of speech tagging**\n",
        "\n",
        "* 사용 및 컨텍스트에 따라 특정 단어 또는 텍스트의 품사를 결정하는 프로세스\n",
        "* 'I can make a paper plane'에서 make 는 동사, 'What make of car do you own?'에서는 명사로 식별"
      ],
      "metadata": {
        "id": "aLP2VWNTHRrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word sense disambiguation**\n",
        "\n",
        "* 주어진 문맥에서 가장 의미가 있는 단어를 결정하는 의미 분석 과정을 통해 여러 의미를 가진 단어의 의미를 선택\n",
        "* make a grade = 성적을 올리다, make a bet = 내기를 하다"
      ],
      "metadata": {
        "id": "pLiPVujAHUoc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Named entity recognition**\n",
        "\n",
        "* 단어나 구를 유용한 엔터티로 식별\n",
        "* 'Kentucky'를 위치로 식별하거나 'Fred'를 남자 이름으로 식별"
      ],
      "metadata": {
        "id": "yTDm-WTuHYor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Co-reference resolution**\n",
        "\n",
        "* 두 단어가 동일한 개체를 참조하는지 여부와 시기를 식별하는 작업\n",
        "* 특정 대명사가 가리키는 사람이나 대상을 결정(she = Mary), 텍스트에서 은유 또는 관용구를 식별하는 것('곰'은 동물이 아니라 털이 많은 사람)"
      ],
      "metadata": {
        "id": "qQveEhntHbqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentiment analysis**\n",
        "\n",
        "* 텍스트에서 태도, 감정, 풍자, 혼란, 의심 등 주관적인 특성을 추출하려고 시도"
      ],
      "metadata": {
        "id": "gjR1PiuHHqvJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natural language generation**\n",
        "\n",
        "*  구조화된 정보를 인간의 언어로 변환하는 작업"
      ],
      "metadata": {
        "id": "iz_iOAkeHr7S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1.3 텍스트 전처리(Text Preprocessing)**"
      ],
      "metadata": {
        "id": "0ocN4wB-N-pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3.1 내장 메서드를 사용한 전처리 (lower, replace, ...)**\n",
        "\n",
        " * Section1,2,3를 하면서 많이 해봤지만 아직도 부족한 부분\n",
        "\n",
        " * 여러데이터를 통해 직접해보면서 경험을 쌓는게 중요하다고 생각함"
      ],
      "metadata": {
        "id": "W_DTUkwpkzc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**1.3.2 정규 표현식(Regular expression, Regex)**\n",
        "\n",
        "* 특정한 규칙을 가진 문자열의 집합을 표현하는 데 사용하는 형식 언어\n",
        "\n",
        "* 예시로 a-z(소문자), A-Z(대문자), 0-9(숫자)를 ^ 제외한 나머지 문자를 잡아낼 수 있는 패턴을 regex 에 할당 .sub 메서드를 통해서 공백 문자열 \"\" 로 치환"
      ],
      "metadata": {
        "id": "NPmL2In3k-Ce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# 1. 파이썬의 정규표현식 패키지 이름은 re 입니다.\n",
        "import re\n",
        "\n",
        "# 2. 정규식 : [] 사이 문자를 매치, ^는 not을 의미합니다.\n",
        "regex = r\"[^a-zA-Z0-9 ]\"\n",
        "\n",
        "# 3. 정규식을 적용할 문자열을 할당합니다.\n",
        "test_str = \"(Natural Language Processing) is easy!, AI!\\n\"\n",
        "\n",
        "# 4. 해당되는 패턴의 문자를 어떤 문자로 바꿀 지를 지정합니다.\n",
        "# ('a', ' ' 등 다른 문자열도 지정해보고 결과를 비교해보세요.)\n",
        "subst = \"\"\n",
        "\n",
        "result = re.sub(regex, subst, test_str)\n",
        "result\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "rH-bowdmuqLk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 정규 표현식에 자주 사용하는 역슬래시(\\\\)를 이용한 문자 규칙\n",
        "\n",
        "| 문자 | 설명 |\n",
        "| - | - |\n",
        "| `\\\\` | 역슬래시 자체를 의미 |\n",
        "| `\\d` | 모든 숫자를 의미, [0-9]와 동일 |\n",
        "| `\\D` | 숫자를 제외한 모든 문자를 의미, [^0-9]와 동일 |\n",
        "| `\\s` | 공백을 의미, [ \\t\\n\\r\\f\\v]와 동일|\n",
        "| `\\S` | 공백을 제외한 모든 문자를 의미, [^ \\t\\n\\r\\f\\v]와 동일 |\n",
        "| `\\w` | 문자와 숫자를 의미, [a-zA-Z0-9]와 동일 |\n",
        "| `\\W` | 문자와 숫자를 제외한 다른 문자를 의미, [^a-zA-Z0-9]와 동일 |\n",
        "\n",
        "* 정규 표현식 문법\n",
        "  \n",
        "| 특수문자 | 설명 |\n",
        "| - | - |\n",
        "| `.` | 앞의 문자 1개를 표현 |\n",
        "| `?` | 문자 한개를 표현하나 존재할 수도, 존재하지 않을 수도 있음(0개 또는 1개) |\n",
        "| `*` | 앞의 문자가 0개 이상 |\n",
        "| `+` | 앞의 문자가 최소 1개 이상 |\n",
        "| `^` | 뒤의 문자로 문자열이 시작 |\n",
        "| `\\$` | 앞의 문자로 문자열이 끝남 |\n",
        "| `\\{n\\}` | `n`번만큼 반복 |\n",
        "| `\\{n1, n2\\}` | `n1` 이상, `n2` 이하만큼 반복, n2를 지정하지 않으면 `n1` 이상만 반복 |\n",
        "| `\\[ abc \\]` | 안에 문자들 중 한 개의 문자와 매치, a-z처럼 범위도 지정 가능 |\n",
        "| `\\[ ^a \\]` | 해당 문자를 제외하고 매치 |\n",
        "| `a\\|b` | `a` 또는 `b`를 나타냄 |"
      ],
      "metadata": {
        "id": "9vI2gAhdwPca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**1.3.3 불용어(Stop words) 처리**\n"
      ],
      "metadata": {
        "id": "Axq6slMyk_f_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 불용어는 이해하는 데에 도움이 안 되기 때문에\n",
        "분석할 때 해당 단어를 제외하면 데이터의 차원을 줄일 수 있음"
      ],
      "metadata": {
        "id": "pNv9aLuXisqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3.4 통계적 트리밍(Trimming)**\n"
      ],
      "metadata": {
        "id": "Y4SGZHbflAlF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 불용어 처리와 같이 직접 단어를 추가하여 제거하지 않고도\n",
        "통계 수치를 통해 말뭉치 내에서 너무 많거나, 적은 토큰을 제거(Trimming)하는 방법"
      ],
      "metadata": {
        "id": "kMD0uDafi3wF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://velog.velcdn.com/images%2Fssu_hyun%2Fpost%2F8b6ab988-f066-4fc4-91e3-c7458c8f1b3a%2Fimage.png' width=300>\n",
        "\n",
        "<sub>이미지 출처 : https://velog.io/@ssu_hyun/N421.%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-%ED%9A%9F%EC%88%98-%EA%B8%B0%EB%B0%98%EC%9D%98-%ED%91%9C%ED%98%84Count-based-Representation"
      ],
      "metadata": {
        "id": "sroRsnYLjDCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **자주 나타나는 단어들 (그래프의 왼쪽)** : 여러 문서에 두루 나타나기 때문에 문서 분류 단계에서 변별력을 제공하지 않음\n",
        "\n",
        "2. **자주 나타나지 않는 단어들 (그래프의 오른쪽)** : 너무 드물게 나타나기 때문에 큰 의미가 없을 확률이 높음"
      ],
      "metadata": {
        "id": "zz60KrjyjRM3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3.5 어간 추출(Stemming) 혹은 표제어 추출(Lemmatization)**"
      ],
      "metadata": {
        "id": "1qqow84olBWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 예를 들어 'batteries' 와 'battery'를 보면 이 둘은 어근(root)이 같은 단어\n",
        "\n",
        "* 어간 추출(stemming)이나 표제어 추출(lemmatization)을 통해 정규화(Normalization)하는 과정이 필요"
      ],
      "metadata": {
        "id": "yEPkNS41jsAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**어간 추출(Stemming)**\n",
        "\n",
        "* 어간 추출은 'ing', 'ed', 's' 등과 같은, 단어의 앞/뒷부분을 단순히 제거"
      ],
      "metadata": {
        "id": "I-np1-HNjwEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**표제어 추출(Lemmatization)**\n",
        "\n",
        "* 표제어 추출을 거친 단어들은 기본 사전형 단어 형태인 Lemma(표제어)로 변환\n",
        "\n",
        "* SpaCy는 표제어 추출 기능을 제공"
      ],
      "metadata": {
        "id": "V9mqWYsFj8b0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "     어간 추출에서는 wolf -> wolf, wolves -> wolv 로 변형\n",
        "\n",
        "     표제어 추출에서는 wolf -> wolf, wolves -> wolf 로 변형"
      ],
      "metadata": {
        "id": "CjtXYdHDkQ3-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.4 등장 횟수 기반의 단어 표현**"
      ],
      "metadata": {
        "id": "01YvOy0WlBvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 머신러닝 모델에서 텍스트를 분석하기 위해서는 벡터화(Vectorization)하는 과정이 필요\n",
        "\n",
        "* 대표적인 방법으로는 Bag-of-Words(TF, TF-IDF) 방식"
      ],
      "metadata": {
        "id": "Mjg5nMHFlEx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.4.1 Bag-of-Words(BoW) : TF(Term Frequency)**"
      ],
      "metadata": {
        "id": "0SPfH9avlRU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 단어의 순서 등은 무시하고 단어들의 빈도만 고려하여 벡터화\n",
        "\n",
        "* 말뭉치에서 모든 고유 단어를 가져와서 발생 빈도를 기록하고 내림차순으로 정렬\n",
        "\n",
        "* 사이킷런(Scikit-learn, Sklearn) 의 CounterVectorizer 를 사용하면 TF 방식으로 문서를 벡터화 가능"
      ],
      "metadata": {
        "id": "LmjteNJzlYpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://miro.medium.com/max/1322/1*3K9GIOVLNu0cRvQap_KaRg.png' width=500>\n",
        "\n",
        "<sub> 이미지 출처 : https://koushik1102.medium.com/nlp-bag-of-words-and-tf-idf-explained-fd1f49dce7c4"
      ],
      "metadata": {
        "id": "GXFZemL_lhPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.4.2 Bag-of-Words(BoW) : TF-IDF (Term Frequency - Inverse Document Frequency)** "
      ],
      "metadata": {
        "id": "atlmlmtNl9v3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 문서에 잘 등장하지 않는 단어라면 해당 문서를 대표할 수 있는 단어가 될 수 있음\n",
        "\n",
        "* 예를 들어 식단표(항상 같은 메뉴도 있지만 그날 대표하는 메뉴가 있음)\n",
        "\n",
        "* 사이킷런(Scikit-learn, Sklearn) 의 TfidfVectorizer를 사용하면 TF-IDF 벡터화도 사용"
      ],
      "metadata": {
        "id": "Weo5ZwY4mXeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.5 K-NearestNeighbor** "
      ],
      "metadata": {
        "id": "ZkQP1KJrm0em"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* K-최근접 이웃법(KNN)은 쿼리와 가장 가까운 상위 K개의 근접한 데이터를 찾아서 데이터의 유사성을 기반으로 점을 추정하거나 분류하는 방법"
      ],
      "metadata": {
        "id": "qHshcdvGm7Fw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고\n",
        "\n",
        "1.1,1.2 https://www.ibm.com/cloud/learn/natural-language-processing#toc-nlp-tools--ZDQeHP8d"
      ],
      "metadata": {
        "id": "_hgWveviNUjn"
      }
    }
  ]
}